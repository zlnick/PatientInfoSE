from http import HTTPStatus
import re
from dotenv import load_dotenv
import os
import uuid
import time
from openai import AsyncOpenAI
from mcp import ClientSession
import chainlit as cl
import json
from utils import parse_mcp_result
from context_manager import IRISContextManager
from planner_agent import generate_plan
import asyncio
import requests
import dashscope
from chainlit.element import ElementBased
from dashscope.audio.tts_v2 import SpeechSynthesizer
from dashscope.common.constants import FilePurpose
from io import BytesIO
import tempfile


load_dotenv()

# åˆå§‹åŒ–IRISä¸Šä¸‹æ–‡ç®¡ç†å™¨
ctx = IRISContextManager(
    host=os.getenv("IRIS_HOSTNAME"),
    port=int(os.getenv("IRIS_PORT")),
    namespace=os.getenv("IRIS_NAMESPACE"),
    username=os.getenv("IRIS_USERNAME"),
    password=os.getenv("IRIS_PASSWORD"),
)

# LLMå®¢æˆ·ç«¯
client = AsyncOpenAI(
    api_key=os.getenv("Qwen_API_KEY"), base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

@cl.on_chat_start
def on_chat_start():
    # æ¯æ¬¡æ–°ä¼šè¯åˆ†é…ä¸€ä¸ªsession_idå¹¶åˆ›å»ºdoc
    session_id = str(uuid.uuid4())
    cl.user_session.set("session_id", session_id)
    cl.user_session.set("counter", 0)
    cl.logger.info(f"æ–°ä¼šè¯åˆ†é… session_id: {session_id}")

@cl.on_mcp_connect
async def on_mcp_connect(connection, session: ClientSession):
    cl.logger.info(f"Chainlit æ­£åœ¨å°è¯•è¿æ¥ MCP Server: {connection.name}")
    try:
        result = await session.list_tools()
        tools = [{"name": t.name, "description": t.description, "input_schema": t.inputSchema} for t in result.tools]
        cl.user_session.set("mcp_tools", {connection.name: tools})
        cl.user_session.set("mcp_session", session)
        cl.logger.info(f"MCP è¿æ¥æˆåŠŸï¼Œå·²è·å– {len(tools)} ä¸ªå·¥å…·")
    except Exception as e:
        cl.logger.error(f"è·å– MCP å·¥å…·åˆ—è¡¨æ—¶å‡ºé”™: {e}")

# context_managerå’Œå…¶ä»–importçœç•¥

def get_or_create_session(cl, ctx):
    session_id = cl.user_session.get("session_id")
    if not session_id:
        session_id = str(uuid.uuid4())
        cl.user_session.set("session_id", session_id)
    # åˆ¤æ–­IRISæ˜¯å¦å·²æœ‰æ­¤sessionï¼Œæ²¡æœ‰æ‰åˆ›å»º
    if ctx.get_session(session_id) is None:
        ctx.create_session(session_id)  # metaå‚æ•°å¯ä»¥çœç•¥
    return session_id

def save_user_message(ctx, session_id, msg):
    ctx.append_history(session_id, "user", msg.content)

def get_history_str(ctx, session_id):
    history = ctx.get_history(session_id)
    return "\n".join([f"{item['role']}: {item['content']}" for item in history]), history

def build_tool_descriptions(mcp_tools):
    if not mcp_tools:
        return ""
    tool_list = list(mcp_tools.values())[0]
    descriptions = []
    for t in tool_list:
        input_schema = t.get('input_schema', {})
        if isinstance(input_schema, dict):
            input_fields = ", ".join([
                f"{k}({(v.get('type') if isinstance(v, dict) else v) or 'æœªçŸ¥ç±»å‹'})"
                for k, v in input_schema.items()
            ]) if input_schema else "æ— è¾“å…¥å­—æ®µ"
        else:
            input_fields = "æœªçŸ¥è¾“å…¥ç»“æ„"
        descriptions.append(f"- {t['name']}: {t['description']} | è¾“å…¥å­—æ®µ: {input_fields}")
    return "\n".join(descriptions)

def compose_prompt(history_str, msg_content, tool_descriptions):
    return f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯æœ¬è½®å¯¹è¯å†å²ï¼š
{history_str}

ç”¨æˆ·æœ€æ–°é—®é¢˜æ˜¯ï¼š"{msg_content}"

ä»¥ä¸‹æ˜¯å½“å‰å¯ç”¨ MCP å·¥å…·åˆ—è¡¨ï¼ŒåŒ…æ‹¬è¾“å…¥å­—æ®µè¯´æ˜ï¼š
{tool_descriptions}

è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1ï¸âƒ£ è‹¥éœ€è¦è°ƒç”¨ MCP å·¥å…·ï¼Œä¸¥æ ¼è¾“å‡ºï¼š
Tool: å·¥å…·åç§°ï¼ˆä¸ä¸Šåˆ—è¡¨å®Œå…¨åŒ¹é…ï¼‰
Input: å·¥å…·è¾“å…¥å‚æ•°ï¼ˆJSONæ ¼å¼ï¼Œå­—æ®µåä¸¥æ ¼å¯¹åº”å·¥å…·å®šä¹‰ï¼‰

2ï¸âƒ£ è‹¥æ— éœ€è°ƒç”¨å·¥å…·ï¼Œè¯·è¾“å‡ºï¼š
Answer: ç›´æ¥å›ç­”å†…å®¹

åˆ‡è®°ï¼š
âœ… å·¥å…·åç§°å’Œå­—æ®µå¿…é¡»ä¸¥æ ¼åŒ¹é…
âœ… ä¸è¦ç”Ÿæˆæ— å…³å­—æ®µ
âœ… å¦‚æœæ²¡æœ‰åˆé€‚å·¥å…·ï¼Œè¯·ç›´æ¥è¾“å‡º Answer
"""

async def call_mcp_tool(session, tool_name, tool_input):
    try:
        result = await session.call_tool(tool_name, tool_input)
        return str(result)
    except Exception as e:
        return f"è°ƒç”¨ MCP å·¥å…·å¤±è´¥: {e}"

def save_assistant_message(ctx, session_id, answer):
    ctx.append_history(session_id, "assistant", answer)

async def send_messages(cl, answer, reasoning_output, counter):
    await cl.Message(content=answer).send()
    await cl.Message(content=f"ğŸ“ æ¨ç†ä¸è°ƒç”¨è¿‡ç¨‹:\n{reasoning_output}").send()
    await cl.Message(content=f"ä½ å·²ç»å‘é€äº† {counter} æ¡æ¶ˆæ¯ï¼").send()

# ===================
# ä¸» on_message æ–¹æ³•
# ===================

@cl.on_message
async def on_message(msg: cl.Message):
    session_id = get_or_create_session(cl, ctx)
    save_user_message(ctx, session_id, msg)
    history_str, history = get_history_str(ctx, session_id)

    mcp_tools = cl.user_session.get("mcp_tools")
    session = cl.user_session.get("mcp_session")

    # === æ–°å¢ï¼šè°ƒç”¨ planner_agent ç”Ÿæˆ plan ===
    # æå–åŸå§‹tools
    tool_list = []
    if mcp_tools:
        for v in mcp_tools.values():
            tool_list.extend(v)

    # ç”Ÿæˆå¤šæ­¥ plan
    plan_json = await generate_plan(history, msg.content, tool_list)
    #cl.logger.error(plan_json)
    plan = plan_json.get("plan", [])
    explanation = plan_json.get("explanation", "")

    process_steps = [f"å¤šæ­¥æ‰§è¡Œè®¡åˆ’ï¼š{json.dumps(plan, ensure_ascii=False, indent=2)}", f"è®¡åˆ’è¯´æ˜ï¼š{explanation}"]

    answer_texts = []

    for idx, step in enumerate(plan):
        action = step.get("action")
        tool = step.get("tool")
        input_data = step.get("input")
        result_var = step.get("result_var")
        step_desc = step.get("description", "")

        process_steps.append(f"Step {idx+1}: {step_desc}")

        if action == "call_tool" and tool and session:
            # è°ƒç”¨ MCP å·¥å…·
            try:
                raw_result = await session.call_tool(tool, input_data)
                parsed_contents = parse_mcp_result(raw_result)
                for content_type, content_value in parsed_contents:
                    if content_type == "text":
                        answer_texts.append(content_value)
                        await cl.Message(content=f"[{tool}] {content_value}").send()
                    elif content_type == "file":
                        await cl.Message(content=f"æ–‡ä»¶é“¾æ¥: {content_value}").send()
                    elif content_type == "image":
                        await cl.Message(content="æ”¶åˆ°å›¾ç‰‡:").send()
                        await cl.Message(image=content_value).send()
                    elif content_type == "error":
                        answer_texts.append(f"âŒ {content_value}")
                        await cl.Message(content=f"âŒ {content_value}").send()
                    else:
                        await cl.Message(content=f"å…¶ä»–å†…å®¹: {content_value}").send()
            except Exception as e:
                err_msg = f"è°ƒç”¨å·¥å…· {tool} å¤±è´¥: {e}"
                answer_texts.append(err_msg)
                await cl.Message(content=err_msg).send()
        elif action == "llm_answer":
            # ç›´æ¥ç”¨LLMè‡ªèº«èƒ½åŠ›ç”Ÿæˆå›ç­”
            llm_prompt = input_data if isinstance(input_data, str) else str(input_data)
            completion = await client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"},
                    {"role": "user", "content": llm_prompt},
                ]
            )
            llm_reply = completion.choices[0].message.content
            answer_texts.append(llm_reply)
            await cl.Message(content=llm_reply).send()
        else:
            # è®¡åˆ’æ ¼å¼ä¸å¯¹
            process_steps.append(f"æ— æ³•è¯†åˆ«çš„è®¡åˆ’ç±»å‹ï¼š{step}")

    # æ±‡æ€»æœ¬è½®å¯¹è¯å†…å®¹è½IRIS
    answer = "\n".join(answer_texts)
    if answer:
        save_assistant_message(ctx, session_id, answer)
    counter = cl.user_session.get("counter")
    counter += 1
    cl.user_session.set("counter", counter)
    process_steps.append(f"ä½ å·²ç»å‘é€äº† {counter} æ¡æ¶ˆæ¯ï¼")
    await cl.Message(content="ğŸ“ æœ¬è½®å¤šæ­¥æ¨ç†/æ‰§è¡Œè¿‡ç¨‹ï¼š\n" + "\n".join(process_steps)).send()


async def speech_to_text(audio_file):
    result = dashscope.Files.upload(file_path=audio_file,
                                    purpose=FilePurpose.assistants)
    file_id = result.output['uploaded_files'][0]['file_id']
    file_res = dashscope.Files.get(file_id)
    task_response = dashscope.audio.asr.Transcription.async_call(
        model='sensevoice-v1',
        file_urls=[file_res.output['url']],
        language_hints=['zh', 'en'],
    )
    transcribe_response = dashscope.audio.asr.Transcription.wait(task=task_response.output.task_id)
    if transcribe_response.status_code == HTTPStatus.OK:
        transcription_url = transcribe_response.output["results"][0]["transcription_url"]
        # å‘é€GETè¯·æ±‚
        response = requests.get(transcription_url)
        # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        if response.status_code == 200:
            # ä½¿ç”¨å†…ç½®çš„json()æ–¹æ³•å°†å“åº”ä½“è§£æä¸ºå­—å…¸
            data = response.json()
            print(data)
            print(data['transcripts'][0]['text'])
            text = data['transcripts'][0]['text']
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ ‡ç­¾ä¹‹é—´çš„æ–‡æœ¬
            pattern = r'<\|Speech\|>(.*?)<\|/Speech\|>'
            match = re.search(pattern, text, re.DOTALL)

            if match:
                text = match.group(1).strip()
            else:
                text = ''
            return text
        else:
            print(f"Failed to retrieve data: {response.status_code}")
    return "fail"

@cl.on_audio_chunk
async def on_audio_chunk(chunk: cl.InputAudioChunk):
    if chunk.isStart:
        buffer = BytesIO()
        buffer.name = f"input_audio.{chunk.mimeType.split('/')[1]}"
        # Initialize the session for a new audio stream
        cl.user_session.set("audio_buffer", buffer)
        cl.user_session.set("audio_mime_type", chunk.mimeType)

    # For now, write the chunks to a buffer and transcribe the whole audio at the end
    cl.user_session.get("audio_buffer").write(chunk.data)


@cl.on_audio_end
async def on_audio_end(elements: list[ElementBased]):
    # Get the audio buffer from the session
    audio_buffer: BytesIO = cl.user_session.get("audio_buffer")
    audio_mime_type: str = cl.user_session.get("audio_mime_type")
    audio_buffer.seek(0)  # å°†æ–‡ä»¶æŒ‡é’ˆç§»åˆ°å¼€å¤´
    # ä½¿ç”¨pydubå¤„ç†éŸ³é¢‘
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as tmpFile:
            tmpFile.write(audio_buffer.read())
            tmpFile_path = tmpFile.name
    except Exception as e:
        print(f"Error processing audio: {e}")

    print('tmpFile_path', tmpFile_path)
    transcription = await speech_to_text(tmpFile_path)
    input_audio_el = cl.Audio(
        mime=audio_mime_type, path=tmpFile_path, name="",
    )
    message = await cl.Message(
        author="You",
        type="user_message",
        content=transcription,
        elements=[input_audio_el, *elements]
    ).send()
    print('transcription', transcription)
    
